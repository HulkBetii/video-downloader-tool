# ui/downloader_ui.py
import tkinter as tk
from tkinter import filedialog, messagebox, ttk
import threading
import os
import sys
import platform

# Add the project root to the path for imports
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
if project_root not in sys.path:
    sys.path.insert(0, project_root)

try:
    from core.downloader import download_video, check_ffmpeg_available
    from utils.system_optimizer import SystemOptimizer
except ImportError:
    # Fallback for when running as script
    core_dir = os.path.join(project_root, 'core')
    utils_dir = os.path.join(project_root, 'utils')
    if core_dir not in sys.path:
        sys.path.insert(0, core_dir)
    if utils_dir not in sys.path:
        sys.path.insert(0, utils_dir)
    try:
        from downloader import download_video, check_ffmpeg_available  # type: ignore
        from system_optimizer import SystemOptimizer  # type: ignore
    except ImportError:
        print("Error: Could not import required modules")
        print("Make sure you're running from the video_downloader_tool directory")
        sys.exit(1)


class VideoDownloaderApp(tk.Tk):
    def __init__(self):
        super().__init__()
        self.title("üé• Video Downloader Tool")
        self.geometry("1280x950")
        self.resizable(False, False)
        self.configure(bg="#f4f6fb")
        self.active_downloads = 0  # ƒê·∫øm s·ªë video ƒëang t·∫£i
        self.active_onedrive_downloads = 0  # ƒê·∫øm s·ªë file OneDrive ƒëang t·∫£i
        self.ffmpeg_available = False
        self.check_dependencies()
        self.create_widgets()
    
    def check_dependencies(self):
        """Ki·ªÉm tra c√°c dependencies c·∫ßn thi·∫øt"""
        missing_deps = []
        
        try:
            import yt_dlp
        except ImportError:
            missing_deps.append("yt-dlp")
        
        try:
            import requests
        except ImportError:
            missing_deps.append("requests")
        
        try:
            import psutil
        except ImportError:
            missing_deps.append("psutil")
        
        if missing_deps:
            print(f"‚ö†Ô∏è Warning: Missing dependencies: {', '.join(missing_deps)}")
            print("üí° Run: pip install -r requirements.txt")

        # Ki·ªÉm tra ffmpeg ƒë·ªÉ ƒëi·ªÅu ch·ªânh UI cho c√°c ch·∫ø ƒë·ªô y√™u c·∫ßu
        try:
            self.ffmpeg_available = check_ffmpeg_available()
        except Exception:
            self.ffmpeg_available = False

    def create_widgets(self):
        # --- Header ---
        header = tk.Frame(self, bg="#3b5998", height=100)
        header.pack(fill="x")
        icon_label = tk.Label(header, text="üé•", font=("Segoe UI Emoji", 32), bg="#3b5998", fg="white")
        icon_label.pack(side="left", padx=(30, 10), pady=10)
        title_label = tk.Label(header, text="Video Downloader Tool", font=("Segoe UI", 22, "bold"), bg="#3b5998", fg="white")
        title_label.pack(side="left", pady=10)

        # --- Main content frame with tabs ---
        self.notebook = ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True, padx=0, pady=(0, 0))
        
        # --- Download Tab ---
        self.download_tab = tk.Frame(self.notebook, bg="#f4f6fb")
        self.notebook.add(self.download_tab, text="üì• T·∫£i Video")
        
        # --- Optimization Tab ---
        self.optimization_tab = tk.Frame(self.notebook, bg="#f4f6fb")
        self.notebook.add(self.optimization_tab, text="‚ö° T·ªëi ∆∞u h√≥a")
        
        # Create download tab content
        self.create_download_tab()
        
        # Create optimization tab content
        self.create_optimization_tab()
        
        # --- Footer ---
        footer = tk.Frame(self, bg="#e3e6f0", height=36)
        footer.pack(fill="x", side="bottom")
        about = tk.Label(footer, text="Make by @ HulkBeoti | 2025", font=("Segoe UI", 9), bg="#e3e6f0", fg="#888")
        about.pack(pady=8)

    def create_download_tab(self):
        """T·∫°o n·ªôi dung cho tab Download v·ªõi layout 2 c·ªôt"""
        main_frame = self.download_tab
        
        # --- Common Settings Section (Top) ---
        common_frame = tk.Frame(main_frame, bg="#f4f6fb", relief="groove", bd=2)
        common_frame.pack(padx=20, pady=(20, 10), fill="x")
        
        # Common Settings Title
        tk.Label(common_frame, text="‚öôÔ∏è C√†i ƒë·∫∑t chung", font=("Segoe UI", 12, "bold"), bg="#f4f6fb", fg="#2c3e50").pack(anchor="w", padx=20, pady=(15, 10))
        
        # Output Folder (Common for both)
        tk.Label(common_frame, text="üíæ Th∆∞ m·ª•c l∆∞u:", font=("Segoe UI", 11, "bold"), bg="#f4f6fb").pack(anchor="w", padx=20, pady=(5, 0))
        path_frame = tk.Frame(common_frame, bg="#f4f6fb")
        path_frame.pack(padx=20, fill="x", pady=(5, 15))
        self.output_entry = tk.Entry(path_frame, font=("Segoe UI", 11), relief="groove", bd=2)
        self.output_entry.pack(side="left", fill="x", expand=True, ipady=5)
        
        # Set default save folder
        try:
            default_download_dir = r"C:\\Users\\HH\\Downloads"
            if os.path.isdir(default_download_dir):
                self.output_entry.delete(0, tk.END)
                self.output_entry.insert(0, default_download_dir)
        except Exception:
            pass
        
        choose_btn = tk.Button(path_frame, text="Ch·ªçn...", command=self.select_output_folder, font=("Segoe UI", 10, "bold"), bg="#3b5998", fg="white", activebackground="#5b7bd5", activeforeground="white", relief="flat", bd=0)
        choose_btn.pack(side="left", padx=8)

        # --- Two Column Layout ---
        columns_frame = tk.Frame(main_frame, bg="#f4f6fb")
        columns_frame.pack(padx=20, pady=10, fill="both", expand=True)
        
        # --- Left Column: Video Download ---
        left_column = tk.Frame(columns_frame, bg="#f4f6fb", relief="groove", bd=2)
        left_column.pack(side="left", fill="both", expand=True, padx=(0, 10))
        
        # Video Download Title
        tk.Label(left_column, text="üé• T·∫£i Video", font=("Segoe UI", 12, "bold"), bg="#f4f6fb", fg="#2c3e50").pack(anchor="w", padx=20, pady=(15, 10))
        
        # Video URL Input
        url_frame = tk.Frame(left_column, bg="#f4f6fb")
        url_frame.pack(padx=20, fill="x", pady=(0, 10))
        tk.Label(url_frame, text="üîó Video URL:", font=("Segoe UI", 11, "bold"), bg="#f4f6fb").pack(anchor="w")
        
        # Create a frame for URL input with line numbers
        url_input_frame = tk.Frame(url_frame, bg="#f4f6fb")
        url_input_frame.pack(fill="x", pady=(5, 0))
        
        # Line numbers frame (left side)
        self.line_numbers = tk.Text(url_input_frame, width=4, height=3, font=("Consolas", 10), 
                                   bg="#f0f0f0", relief="sunken", bd=1, state="disabled")
        self.line_numbers.pack(side="left", fill="y")
        
        # URL input frame (right side)
        self.url_entry = tk.Text(url_input_frame, width=40, height=3, font=("Segoe UI", 11), 
                                relief="groove", bd=2, wrap="none")
        self.url_entry.pack(side="left", fill="x", expand=True, padx=(5, 0))
        
        # Scrollbar for URL input
        url_scrollbar = ttk.Scrollbar(url_input_frame, orient="vertical", command=self.url_entry.yview)
        self.url_entry.configure(yscrollcommand=url_scrollbar.set)
        url_scrollbar.pack(side="right", fill="y")
        
        # Bind events to update line numbers and handle URL input
        self.url_entry.bind('<Key>', self.update_line_numbers)
        self.url_entry.bind('<KeyRelease>', self.update_line_numbers)
        self.url_entry.bind('<Button-1>', self.update_line_numbers)
        self.url_entry.bind('<KeyRelease>', self.highlight_current_line)
        
        # Initialize line numbers
        self.update_line_numbers()

        # Optimization Mode
        tk.Label(left_column, text="‚ö° Ch·∫ø ƒë·ªô t·ªëi ∆∞u h√≥a:", font=("Segoe UI", 11, "bold"), bg="#f4f6fb").pack(anchor="w", padx=20, pady=(10, 0))
        # Default to quality mode; will fallback to balanced if ffmpeg unavailable
        self.optimize_mode = tk.StringVar(value="quality")
        optimize_frame = tk.Frame(left_column, bg="#f4f6fb")
        optimize_frame.pack(padx=20, fill="x", pady=(0, 10))
        style = {"font": ("Segoe UI", 9), "bg": "#f4f6fb"}
        tk.Radiobutton(optimize_frame, text="C√¢n b·∫±ng", variable=self.optimize_mode, value="balanced", selectcolor="#e3e6f0", **style).pack(anchor="w", pady=2)
        tk.Radiobutton(optimize_frame, text="T·ªëc ƒë·ªô cao", variable=self.optimize_mode, value="speed", selectcolor="#e3e6f0", **style).pack(anchor="w", pady=2)
        self.rb_quality = tk.Radiobutton(optimize_frame, text="Ch·∫•t l∆∞·ª£ng cao", variable=self.optimize_mode, value="quality", selectcolor="#e3e6f0", **style)
        self.rb_quality.pack(anchor="w", pady=2)
        self.rb_speed_quality = tk.Radiobutton(optimize_frame, text="üöÄ T·ªëc ƒë·ªô + Ch·∫•t l∆∞·ª£ng", variable=self.optimize_mode, value="speed_quality", selectcolor="#e3e6f0", **style)
        self.rb_speed_quality.pack(anchor="w", pady=2)

        # V√¥ hi·ªáu h√≥a c√°c ch·∫ø ƒë·ªô y√™u c·∫ßu ffmpeg n·∫øu ffmpeg kh√¥ng c√≥ s·∫µn
        if not self.ffmpeg_available:
            try:
                self.rb_quality.config(state="disabled")
                self.rb_speed_quality.config(state="disabled")
                tk.Label(left_column, text="‚ö†Ô∏è ffmpeg ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t. C√°c ch·∫ø ƒë·ªô ch·∫•t l∆∞·ª£ng ƒë√£ b·ªã v√¥ hi·ªáu.", font=("Segoe UI", 9), bg="#f4f6fb", fg="#ff9800").pack(anchor="w", padx=20, pady=(0, 5))
                # Fallback selection if default was quality
                if self.optimize_mode.get() in ("quality", "speed_quality"):
                    self.optimize_mode.set("balanced")
            except Exception:
                pass

        # Video Cookie file
        self.use_cookies = tk.BooleanVar()
        tk.Checkbutton(left_column, text="D√πng cookie file (.txt/.json)", variable=self.use_cookies, command=self.toggle_cookie_entry, font=("Segoe UI", 10), bg="#f4f6fb").pack(anchor="w", padx=20, pady=(5, 0))
        cookie_frame = tk.Frame(left_column, bg="#f4f6fb")
        cookie_frame.pack(padx=20, fill="x", pady=(5, 10))
        self.cookie_entry = tk.Entry(cookie_frame, state="disabled", font=("Segoe UI", 10), relief="groove", bd=2)
        self.cookie_entry.pack(side="left", fill="x", expand=True, ipady=4)
        cookie_btn = tk.Button(cookie_frame, text="Ch·ªçn...", command=self.select_cookie_file, font=("Segoe UI", 10, "bold"), bg="#3b5998", fg="white", activebackground="#5b7bd5", activeforeground="white", relief="flat", bd=0)
        cookie_btn.pack(side="left", padx=8)

        # # Video Progress Bar
        # self.progress_frame = tk.Frame(left_column, bg="#f4f6fb")
        # self.progress_frame.pack(padx=20, pady=(10, 0), fill="x")
        
        # # Main progress bar
        # self.progress_bar = ttk.Progressbar(self.progress_frame, mode='indeterminate')
        # self.progress_bar.pack(fill="x")
        
        # # Detailed progress info frame
        # self.detailed_progress_frame = tk.Frame(left_column, bg="#f4f6fb")
        # self.detailed_progress_frame.pack(padx=20, pady=(5, 0), fill="x")
        
        # # Fragment progress label
        # self.fragment_progress_label = tk.Label(self.detailed_progress_frame, text="", font=("Segoe UI", 9), 
        #                                       bg="#f4f6fb", fg="#666", justify="left")
        # self.fragment_progress_label.pack(anchor="w")
        
        # # Download speed and ETA label
        # self.speed_eta_label = tk.Label(self.detailed_progress_frame, text="", font=("Segoe UI", 9), 
        #                                bg="#f4f6fb", fg="#666", justify="left")
        # self.speed_eta_label.pack(anchor="w")

        # Video Download Button
        self.download_button = tk.Button(left_column, text="üé• T·∫£i Video", command=self.start_download, font=("Segoe UI", 12, "bold"), bg="#28a745", fg="white", activebackground="#218838", activeforeground="white", relief="flat", bd=0, height=2)
        self.download_button.pack(pady=15, ipadx=10, ipady=2)
        
        # Video Status
        self.status_label = tk.Label(left_column, text="S·∫µn s√†ng t·∫£i video.", fg="#3b5998", bg="#f4f6fb", font=("Segoe UI", 10, "italic"), wraplength=250)
        self.status_label.pack(pady=5)
        
        # --- Right Column: OneDrive File Download ---
        right_column = tk.Frame(columns_frame, bg="#f4f6fb", relief="groove", bd=2)
        right_column.pack(side="right", fill="both", expand=True, padx=(10, 0))
        
        # OneDrive Title
        tk.Label(right_column, text="üìÅ T·∫£i File OneDrive/SharePoint", font=("Segoe UI", 12, "bold"), bg="#f4f6fb", fg="#2c3e50").pack(anchor="w", padx=20, pady=(15, 10))
        
        # H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng
        help_text = "üí° H·ªó tr·ª£: .rar, .zip, .pdf, .docx, .xlsx, .mp3, .mp4 v√† nhi·ªÅu ƒë·ªãnh d·∫°ng kh√°c"
        help_text2 = "üåê H·ªó tr·ª£: OneDrive, SharePoint, Office 365"
        tk.Label(right_column, text=help_text, font=("Segoe UI", 9), bg="#f4f6fb", fg="#7f8c8d").pack(anchor="w", padx=20, pady=(0, 5))
        tk.Label(right_column, text=help_text2, font=("Segoe UI", 9), bg="#f4f6fb", fg="#7f8c8d").pack(anchor="w", padx=20, pady=(0, 10))
        
        # OneDrive URL Input
        onedrive_url_frame = tk.Frame(right_column, bg="#f4f6fb")
        onedrive_url_frame.pack(padx=20, fill="x", pady=(0, 10))
        tk.Label(onedrive_url_frame, text="üîó OneDrive/SharePoint URL:", font=("Segoe UI", 11, "bold"), bg="#f4f6fb").pack(anchor="w")
        
        # Create a frame for OneDrive URL input with line numbers
        onedrive_url_input_frame = tk.Frame(onedrive_url_frame, bg="#f4f6fb")
        onedrive_url_input_frame.pack(fill="x", pady=(5, 0))
        
        # Line numbers frame (left side)
        self.onedrive_line_numbers = tk.Text(onedrive_url_input_frame, width=4, height=3, font=("Consolas", 10), 
                                            bg="#f0f0f0", relief="sunken", bd=1, state="disabled")
        self.onedrive_line_numbers.pack(side="left", fill="y")
        
        # OneDrive URL input frame (right side)
        self.onedrive_url_entry = tk.Text(onedrive_url_input_frame, width=40, height=3, font=("Segoe UI", 11), 
                                         relief="groove", bd=2, wrap="none")
        self.onedrive_url_entry.pack(side="left", fill="x", expand=True, padx=(5, 0))
        
        # Scrollbar for OneDrive URL input
        onedrive_url_scrollbar = ttk.Scrollbar(onedrive_url_input_frame, orient="vertical", command=self.onedrive_url_entry.yview)
        self.onedrive_url_entry.configure(yscrollcommand=onedrive_url_scrollbar.set)
        onedrive_url_scrollbar.pack(side="right", fill="y")
        
        # Bind events to update line numbers and handle OneDrive URL input
        self.onedrive_url_entry.bind('<Key>', self.update_onedrive_line_numbers)
        self.onedrive_url_entry.bind('<KeyRelease>', self.update_onedrive_line_numbers)
        self.onedrive_url_entry.bind('<Button-1>', self.update_onedrive_line_numbers)
        self.onedrive_url_entry.bind('<KeyRelease>', self.highlight_onedrive_current_line)
        
        # Initialize OneDrive line numbers
        self.update_onedrive_line_numbers()

        # OneDrive Cookie file
        self.onedrive_use_cookies = tk.BooleanVar()
        tk.Checkbutton(right_column, text="D√πng cookie file cho OneDrive", variable=self.onedrive_use_cookies, command=self.toggle_onedrive_cookie_entry, font=("Segoe UI", 10), bg="#f4f6fb").pack(anchor="w", padx=20, pady=(10, 0))
        onedrive_cookie_frame = tk.Frame(right_column, bg="#f4f6fb")
        onedrive_cookie_frame.pack(padx=20, fill="x", pady=(5, 10))
        self.onedrive_cookie_entry = tk.Entry(onedrive_cookie_frame, state="disabled", font=("Segoe UI", 10), relief="groove", bd=2)
        self.onedrive_cookie_entry.pack(side="left", fill="x", expand=True, ipady=4)
        onedrive_cookie_btn = tk.Button(onedrive_cookie_frame, text="Ch·ªçn...", command=self.select_onedrive_cookie_file, font=("Segoe UI", 10, "bold"), bg="#e67e22", fg="white", activebackground="#d35400", activeforeground="white", relief="flat", bd=0)
        onedrive_cookie_btn.pack(side="left", padx=8)
        
        # OneDrive Progress Bar
        self.onedrive_progress_frame = tk.Frame(right_column, bg="#f4f6fb")
        self.onedrive_progress_frame.pack(padx=20, pady=(10, 0), fill="x")
        self.onedrive_progress_bar = ttk.Progressbar(self.onedrive_progress_frame, mode='indeterminate')
        self.onedrive_progress_bar.pack(fill="x")
        
        # OneDrive Download Button
        self.onedrive_download_button = tk.Button(right_column, text="üìÅ T·∫£i File OneDrive/SharePoint", command=self.start_onedrive_download, font=("Segoe UI", 12, "bold"), bg="#e67e22", fg="white", activebackground="#d35400", activeforeground="white", relief="flat", bd=0, height=2)
        self.onedrive_download_button.pack(pady=15, ipadx=10, ipady=2)
        
        # OneDrive Status
        self.onedrive_status_label = tk.Label(right_column, text="S·∫µn s√†ng t·∫£i file t·ª´ OneDrive/SharePoint.", fg="#e67e22", bg="#f4f6fb", font=("Segoe UI", 10, "italic"), wraplength=250)
        self.onedrive_status_label.pack(pady=5)

    def create_optimization_tab(self):
        """T·∫°o n·ªôi dung cho tab T·ªëi ∆∞u h√≥a"""
        main_frame = self.optimization_tab
        
        # Initialize system optimizer
        try:
            self.system_optimizer = SystemOptimizer()
        except Exception as e:
            self.system_optimizer = None
            print(f"Warning: Could not initialize SystemOptimizer: {e}")
        
        # --- System Info Section ---
        info_frame = tk.Frame(main_frame, bg="#f4f6fb", relief="groove", bd=2)
        info_frame.pack(padx=40, pady=(30, 20), fill="x")
        
        tk.Label(info_frame, text="üñ•Ô∏è Th√¥ng tin h·ªá th·ªëng", font=("Segoe UI", 12, "bold"), bg="#f4f6fb").pack(anchor="w", padx=20, pady=(15, 10))
        
        if self.system_optimizer:
            # System specs
            specs_frame = tk.Frame(info_frame, bg="#f4f6fb")
            specs_frame.pack(padx=20, fill="x", pady=(0, 15))
            
            specs_text = f"üíª CPU: {self.system_optimizer.cpu_count} cores\n"
            specs_text += f"üíæ RAM: {self.system_optimizer.memory_gb:.1f} GB\n"
            specs_text += f"üñ•Ô∏è  OS: {platform.system()} {platform.release()}"
            
            tk.Label(specs_frame, text=specs_text, font=("Segoe UI", 10), bg="#f4f6fb", justify="left").pack(anchor="w")
        else:
            tk.Label(info_frame, text="‚ö†Ô∏è Kh√¥ng th·ªÉ l·∫•y th√¥ng tin h·ªá th·ªëng", font=("Segoe UI", 10), bg="#f4f6fb", fg="orange").pack(padx=20, pady=(0, 15))
        
        # --- Performance Report Section ---
        perf_frame = tk.Frame(main_frame, bg="#f4f6fb", relief="groove", bd=2)
        perf_frame.pack(padx=40, pady=(0, 20), fill="x")
        
        tk.Label(perf_frame, text="üìä B√°o c√°o hi·ªáu su·∫•t", font=("Segoe UI", 12, "bold"), bg="#f4f6fb").pack(anchor="w", padx=20, pady=(15, 10))
        
        self.perf_text = tk.Text(perf_frame, height=8, font=("Consolas", 9), bg="#f8f9fa", relief="sunken", bd=1)
        self.perf_text.pack(padx=20, pady=(0, 15), fill="x")
        
        # Refresh button
        refresh_btn = tk.Button(perf_frame, text="üîÑ L√†m m·ªõi", command=self.refresh_performance, font=("Segoe UI", 10, "bold"), bg="#17a2b8", fg="white", activebackground="#138496", activeforeground="white", relief="flat", bd=0)
        refresh_btn.pack(pady=(0, 15))
        
        # --- Optimization Tips Section ---
        tips_frame = tk.Frame(main_frame, bg="#f4f6fb", relief="groove", bd=2)
        tips_frame.pack(padx=40, pady=(0, 20), fill="x")
        
        tk.Label(tips_frame, text="üí° M·∫πo t·ªëi ∆∞u h√≥a", font=("Segoe UI", 12, "bold"), bg="#f4f6fb").pack(anchor="w", padx=20, pady=(15, 10))
        
        self.tips_text = tk.Text(tips_frame, height=10, font=("Segoe UI", 9), bg="#f8f9fa", relief="sunken", bd=1, wrap="word")
        self.tips_text.pack(padx=20, pady=(0, 15), fill="x")
        
        # Load initial data
        self.refresh_performance()
        self.load_optimization_tips()

    def select_output_folder(self):
        folder = filedialog.askdirectory()
        if folder:
            self.output_entry.delete(0, tk.END)
            self.output_entry.insert(0, folder)

    def select_cookie_file(self):
        file = filedialog.askopenfilename(
            filetypes=[
                ("Cookie files", "*.txt;*.json"),
                ("Text files", "*.txt"),
                ("JSON files", "*.json"),
                ("All files", "*.*")
            ]
        )
        if file:
            self.cookie_entry.delete(0, tk.END)
            self.cookie_entry.insert(0, file)

    def select_onedrive_cookie_file(self):
        file = filedialog.askopenfilename(
            filetypes=[
                ("Cookie files", "*.txt;*.json"),
                ("Text files", "*.txt"),
                ("JSON files", "*.json"),
                ("All files", "*.*")
            ]
        )
        if file:
            self.onedrive_cookie_entry.delete(0, tk.END)
            self.onedrive_cookie_entry.insert(0, file)

    def toggle_onedrive_cookie_entry(self):
        state = "normal" if self.onedrive_use_cookies.get() else "disabled"
        self.onedrive_cookie_entry.config(state=state)

    def toggle_cookie_entry(self):
        state = "normal" if self.use_cookies.get() else "disabled"
        self.cookie_entry.config(state=state)

    def start_download(self):
        url_text = self.url_entry.get("1.0", tk.END)
        urls = [u.strip() for u in url_text.splitlines() if u.strip()]
        output_folder = self.output_entry.get().strip()
        cookie_file = self.cookie_entry.get().strip() if self.use_cookies.get() else None
        optimize_mode = self.optimize_mode.get()

        if not urls or not output_folder:
            messagebox.showerror("Thi·∫øu th√¥ng tin", "Vui l√≤ng nh·∫≠p URL v√† ch·ªçn th∆∞ m·ª•c l∆∞u.")
            return

        self.download_button.config(state="disabled")
        # Start progress if widget exists
        if hasattr(self, 'progress_bar') and self.progress_bar:
            try:
                self.progress_bar.start()
            except Exception:
                pass
        
        # X√≥a th√¥ng tin ti·∫øn tr√¨nh c≈© (n·∫øu c√≥ label)
        self.clear_progress_display()
        
        # Hi·ªÉn th·ªã danh s√°ch URL v·ªõi s·ªë th·ª© t·ª±
        url_list = []
        for i, url in enumerate(urls, 1):
            formatted_url = self.format_url_for_display(url, i)
            url_list.append(formatted_url)
        
        status_text = f"‚è≥ ƒêang t·∫£i {len(urls)} video:\n" + "\n".join(url_list)
        self.status_label.config(text=status_text, fg="#ff9800")
        
        self.active_downloads = len(urls)
        for i, url in enumerate(urls, 1):
            threading.Thread(target=self.run_download, args=(url, output_folder, cookie_file, optimize_mode, i)).start()

    def run_download(self, url, output_folder, cookie_file, optimize_mode, line_number):
        def update_status(status_text, color="#3b5998"):
            # Th√™m s·ªë th·ª© t·ª± v√†o th√¥ng b√°o tr·∫°ng th√°i
            if "ƒêang t·∫£i" in status_text:
                status_text = f"[{line_number}] {status_text}"
                
                # Parse th√¥ng tin fragment t·ª´ status_text
                self.parse_and_display_progress(status_text, line_number)
            elif "Ho√†n t·∫•t" in status_text:
                status_text = f"[{line_number}] {status_text}"
                # X√≥a th√¥ng tin fragment khi ho√†n t·∫•t
                self.clear_progress_display()
            elif "L·ªói" in status_text:
                status_text = f"[{line_number}] {status_text}"
                # X√≥a th√¥ng tin fragment khi c√≥ l·ªói
                self.clear_progress_display()
            
            self.status_label.config(text=status_text, fg=color)

        try:
            download_video(url, output_folder, cookie_file, status_callback=update_status, optimize_mode=optimize_mode)
        except Exception as e:
            update_status(f"‚ùå L·ªói: {e}", "red")
        finally:
            self.active_downloads -= 1
            if self.active_downloads <= 0:
                # Stop progress if widget exists
                if hasattr(self, 'progress_bar') and self.progress_bar:
                    try:
                        self.progress_bar.stop()
                    except Exception:
                        pass
                self.download_button.config(state="normal")
                self.status_label.config(text="‚úÖ ƒê√£ t·∫£i xong t·∫•t c·∫£ video!", fg="#28a745")
                self.clear_progress_display()
            else:
                self.status_label.config(text=f"‚è≥ ƒêang t·∫£i {self.active_downloads} video c√≤n l·∫°i...", fg="#ff9800")

    def start_onedrive_download(self):
        """B·∫Øt ƒë·∫ßu t·∫£i file t·ª´ OneDrive/SharePoint"""
        onedrive_url_text = self.onedrive_url_entry.get("1.0", tk.END)
        onedrive_urls = [u.strip() for u in onedrive_url_text.splitlines() if u.strip()]
        output_folder = self.output_entry.get().strip()
        cookie_file = self.onedrive_cookie_entry.get().strip() if self.onedrive_use_cookies.get() else None

        if not onedrive_urls or not output_folder:
            messagebox.showerror("Thi·∫øu th√¥ng tin", "Vui l√≤ng nh·∫≠p OneDrive/SharePoint URL v√† ch·ªçn th∆∞ m·ª•c l∆∞u.")
            return

        # Ki·ªÉm tra URL OneDrive/SharePoint
        invalid_urls = []
        for url in onedrive_urls:
            if not self.is_onedrive_url(url):
                invalid_urls.append(url)
        
        if invalid_urls:
            error_msg = "C√°c URL sau kh√¥ng ph·∫£i OneDrive/SharePoint h·ª£p l·ªá:\n"
            for i, url in enumerate(invalid_urls, 1):
                formatted_url = self.format_url_for_display(url, i)
                error_msg += f"{formatted_url}\n"
            messagebox.showerror("URL kh√¥ng h·ª£p l·ªá", error_msg)
            return

        self.onedrive_download_button.config(state="disabled")
        # Start progress if widget exists
        if hasattr(self, 'onedrive_progress_bar') and self.onedrive_progress_bar:
            try:
                self.onedrive_progress_bar.start()
            except Exception:
                pass
        
        # X√≥a th√¥ng tin ti·∫øn tr√¨nh c≈©
        self.clear_progress_display()
        
        # Hi·ªÉn th·ªã danh s√°ch URL v·ªõi s·ªë th·ª© t·ª±
        url_list = []
        for i, url in enumerate(onedrive_urls, 1):
            formatted_url = self.format_url_for_display(url, i)
            url_list.append(formatted_url)
        
        status_text = f"‚è≥ ƒêang t·∫£i {len(onedrive_urls)} file t·ª´ OneDrive/SharePoint:\n" + "\n".join(url_list)
        self.onedrive_status_label.config(text=status_text, fg="#e67e22")
        self.active_onedrive_downloads = len(onedrive_urls)
        
        # Ch·∫°y t·∫£i file trong thread ri√™ng cho m·ªói URL
        for i, url in enumerate(onedrive_urls, 1):
            threading.Thread(target=self.run_onedrive_download, args=(url, output_folder, cookie_file, i)).start()

    def run_onedrive_download(self, onedrive_url, output_folder, cookie_file, line_number):
        """Ch·∫°y t·∫£i file OneDrive/SharePoint trong thread ri√™ng"""
        def update_status(status_text, color="#e67e22"):
            # Th√™m s·ªë th·ª© t·ª± v√†o th√¥ng b√°o tr·∫°ng th√°i
            if "ƒêang t·∫£i" in status_text:
                status_text = f"[{line_number}] {status_text}"
            elif "Ho√†n t·∫•t" in status_text:
                status_text = f"[{line_number}] {status_text}"
            elif "L·ªói" in status_text:
                status_text = f"[{line_number}] {status_text}"
            elif "ƒêang ki·ªÉm tra" in status_text:
                status_text = f"[{line_number}] {status_text}"
            elif "Ph√°t hi·ªán" in status_text:
                status_text = f"[{line_number}] {status_text}"
            
            self.onedrive_status_label.config(text=status_text, fg=color)

        try:
            # S·ª≠ d·ª•ng yt-dlp ƒë·ªÉ t·∫£i file t·ª´ OneDrive/SharePoint
            self.download_onedrive_file(onedrive_url, output_folder, cookie_file, update_status)
        except Exception as e:
            update_status(f"‚ùå L·ªói: {e}", "red")
        finally:
            self.active_onedrive_downloads -= 1
            if self.active_onedrive_downloads <= 0:
                # Stop progress if widget exists
                if hasattr(self, 'onedrive_progress_bar') and self.onedrive_progress_bar:
                    try:
                        self.onedrive_progress_bar.stop()
                    except Exception:
                        pass
                self.onedrive_download_button.config(state="normal")
                self.onedrive_status_label.config(text="‚úÖ ƒê√£ t·∫£i xong t·∫•t c·∫£ file!", fg="#27ae60")
            else:
                self.onedrive_status_label.config(text=f"‚è≥ ƒêang t·∫£i {self.active_onedrive_downloads} file c√≤n l·∫°i...", fg="#e67e22")

    def download_onedrive_file(self, onedrive_url, output_folder, cookie_file, status_callback):
        """T·∫£i file t·ª´ OneDrive/SharePoint s·ª≠ d·ª•ng yt-dlp"""
        try:
            import yt_dlp
            
            # Debug: Ki·ªÉm tra URL
            status_callback(f"üîç ƒêang ki·ªÉm tra URL: {onedrive_url[:100]}...", "blue")
            
            # Ki·ªÉm tra n·∫øu l√† SharePoint URL ph·ª©c t·∫°p
            if self.is_complex_sharepoint_url(onedrive_url):
                status_callback("üîç Ph√°t hi·ªán SharePoint URL ph·ª©c t·∫°p, ƒëang x·ª≠ l√Ω...", "blue")
                return self.handle_complex_sharepoint(onedrive_url, output_folder, cookie_file, status_callback)
            else:
                status_callback("üîç Kh√¥ng ph·∫£i SharePoint URL ph·ª©c t·∫°p, s·ª≠ d·ª•ng yt-dlp...", "blue")
            
            # C·∫•u h√¨nh yt-dlp cho OneDrive/SharePoint
            ydl_opts = {
                'outtmpl': os.path.join(output_folder, '%(title)s.%(ext)s'),
                'quiet': False,
                'noplaylist': True,
                'restrictfilenames': False,
                'concurrent_fragment_downloads': 8,
                'buffersize': 2048,
                'http_chunk_size': 10485760,  # 10MB chunks
                'retries': 5,  # TƒÉng retry cho SharePoint
                'fragment_retries': 5,
                'socket_timeout': 60,  # TƒÉng timeout cho SharePoint
                'ignoreerrors': False,
                'no_warnings': False,
                'extractor_retries': 5,  # TƒÉng retry cho extractor
                'fragment_retries': 5,
                'skip_unavailable_fragments': True,
            }

            # Th√™m cookies n·∫øu c√≥
            if cookie_file:
                ydl_opts['cookiefile'] = cookie_file
                status_callback("üç™ S·ª≠ d·ª•ng cookies cho OneDrive/SharePoint", "blue")
                
                # Ki·ªÉm tra cookies c√≥ h·ª£p l·ªá kh√¥ng
                try:
                    from utils.cookies import is_valid_cookie_file
                    if is_valid_cookie_file(cookie_file):
                        status_callback("‚úÖ Cookies h·ª£p l·ªá", "green")
                    else:
                        status_callback("‚ö†Ô∏è Cookies c√≥ th·ªÉ kh√¥ng h·ª£p l·ªá", "orange")
                except ImportError:
                    status_callback("üç™ Cookies ƒë√£ ƒë∆∞·ª£c th√™m", "blue")
            
            # X·ª≠ l√Ω ƒë·∫∑c bi·ªát cho SharePoint URLs
            if 'sharepoint.com' in onedrive_url.lower():
                status_callback("üîç Ph√°t hi·ªán SharePoint URL, ƒëang x·ª≠ l√Ω...", "blue")
                
                # X·ª≠ l√Ω ƒë·∫∑c bi·ªát cho SharePoint sharing URLs (:u:/r/)
                if ':u:/r/' in onedrive_url:
                    status_callback("üîç Ph√°t hi·ªán SharePoint sharing URL, ƒëang x·ª≠ l√Ω...", "blue")
                    # Th·ª≠ chuy·ªÉn ƒë·ªïi URL sharing th√†nh URL download
                    converted_url = self.convert_sharepoint_sharing_url(onedrive_url)
                    if converted_url:
                        status_callback(f"üîÑ ƒê√£ chuy·ªÉn ƒë·ªïi URL: {converted_url[:100]}...", "blue")
                        onedrive_url = converted_url
                
                # Th√™m headers ƒë·∫∑c bi·ªát cho SharePoint
                ydl_opts['http_headers'] = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                    'Accept-Language': 'en-US,en;q=0.5',
                    'Accept-Encoding': 'gzip, deflate',
                    'DNT': '1',
                    'Connection': 'keep-alive',
                    'Upgrade-Insecure-Requests': '1',
                    'Referer': 'https://moithuvemmo-my.sharepoint.com/',
                }
                # TƒÉng timeout cho SharePoint
                ydl_opts['socket_timeout'] = 120
                ydl_opts['extractor_retries'] = 10
                
                # Th√™m extractor args ƒë·∫∑c bi·ªát cho SharePoint
                ydl_opts['extractor_args'] = {
                    'generic': {
                        'extract_flat': False,
                        'no_warnings': False,
                    }
                }

            def progress_hook(d):
                if d['status'] == 'downloading':
                    percent = d.get('_percent_str', '').strip()
                    speed = d.get('_speed_str', '').strip()
                    eta = d.get('eta_str', '').strip()
                    if status_callback:
                        status_text = f"üì• ƒêang t·∫£i: {percent} | T·ªëc ƒë·ªô: {speed}"
                        if eta:
                            status_text += f" | C√≤n l·∫°i: {eta}"
                        status_callback(status_text, "blue")
                elif d['status'] == 'finished':
                    if status_callback:
                        status_callback("‚úÖ Ho√†n t·∫•t t·∫£i file!", "green")

            ydl_opts['progress_hooks'] = [progress_hook]

            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                status_callback("üîç ƒêang ph√¢n t√≠ch URL OneDrive...", "blue")
                ydl.download([onedrive_url])

        except ImportError:
            status_callback("‚ùå L·ªói: yt-dlp kh√¥ng ƒë∆∞·ª£c c√†i ƒë·∫∑t", "red")
        except Exception as e:
            status_callback(f"‚ùå L·ªói khi t·∫£i file: {str(e)}", "red")

    def is_onedrive_url(self, url):
        """Ki·ªÉm tra xem URL c√≥ ph·∫£i l√† OneDrive/SharePoint kh√¥ng"""
        onedrive_domains = [
            '1drv.ms',
            'onedrive.live.com',
            'sharepoint.com',
            'office.com',
            'moithuvemmo-my.sharepoint.com'  # Custom SharePoint domain
        ]
        return any(domain in url.lower() for domain in onedrive_domains)
    
    def is_complex_sharepoint_url(self, url):
        """Ki·ªÉm tra xem c√≥ ph·∫£i SharePoint URL ph·ª©c t·∫°p kh√¥ng"""
        url_lower = url.lower()
        
        # Debug logging
        print(f"üîç Debug: Ki·ªÉm tra URL: {url[:100]}...")
        print(f"üîç Debug: sharepoint.com in URL: {'sharepoint.com' in url_lower}")
        print(f"üîç Debug: :u:/r/ in URL: {':u:/r/' in url}")
        print(f"üîç Debug: _layouts/15/onedrive.aspx in URL: {'_layouts/15/onedrive.aspx' in url_lower}")
        print(f"üîç Debug: id= in URL: {'id=' in url_lower}")
        print(f"üîç Debug: parent= in URL: {'parent=' in url_lower}")
        print(f"üîç Debug: URL length: {len(url)}")
        
        is_complex = ('sharepoint.com' in url_lower and 
                (':u:/r/' in url or  # SharePoint sharing URL format
                 '_layouts/15/onedrive.aspx' in url_lower or 
                 'id=' in url_lower or 
                 'parent=' in url_lower or
                 len(url) > 200))  # Gi·∫£m ng∆∞·ª°ng ƒë·ªÉ b·∫Øt nhi·ªÅu URL h∆°n
        
        print(f"üîç Debug: Is complex SharePoint URL: {is_complex}")
        return is_complex
    
    def handle_complex_sharepoint(self, url, output_folder, cookie_file, status_callback):
        """
        Enhanced SharePoint download handler with proper URL parsing
        """
        try:
            import requests
            import urllib.parse
            import os
            import re
            
            status_callback("üîÑ Enhanced SharePoint download starting...", "blue")
            
            # Step 1: Extract filename properly
            filename = self.extract_filename_from_url(url)
            status_callback(f"üìÅ Detected filename: {filename}", "green")
            
            # Step 2: Create session with proper headers
            session = requests.Session()
            
            # Load cookies if available
            if cookie_file and os.path.exists(cookie_file):
                try:
                    from utils.cookies import load_cookies_from_file
                    cookies = load_cookies_from_file(cookie_file)
                    if cookies:
                        session.cookies.update(cookies)
                        status_callback(f"üç™ Loaded {len(cookies)} cookies", "green")
                        
                        # Add SharePoint-specific cookies if missing
                        sharepoint_cookies = {
                            'SPOIDCRL': '1',  # SharePoint Online IDCRL
                            'WSS_FullScreenMode': 'false',
                            'SPRequestGuid': '1',
                            'SPOIDCRL': '1'
                        }
                        
                        # Only add if not already present
                        for name, value in sharepoint_cookies.items():
                            if name not in session.cookies:
                                session.cookies.set(name, value, domain='.sharepoint.com')
                        
                        print(f"üîç Debug: Enhanced with SharePoint cookies")
                        
                except Exception as e:
                    status_callback(f"Warning: Cookie loading failed: {e}", "orange")
            
            # Step 3: Try multiple download approaches
            download_success = False
            
            # Approach 1: Convert sharing URL to direct download URL
            status_callback("üîÑ Trying direct URL conversion...", "blue")
            direct_urls = self.create_multiple_download_urls(url)
            
            for i, direct_url in enumerate(direct_urls):
                if direct_url:
                    status_callback(f"üîó Trying download URL #{i+1}...", "blue")
                    print(f"üîç Debug: Attempting URL: {direct_url[:100]}...")
                    
                    if self.download_from_url(direct_url, output_folder, filename, session, status_callback):
                        download_success = True
                        break
            
            # Approach 2: Parse SharePoint page for download links
            if not download_success:
                status_callback("üîÑ Trying page parsing method...", "blue")
                download_links = self.extract_download_links_from_page(url, session, status_callback)
                
                for link in download_links:
                    if self.download_from_url(link, output_folder, filename, session, status_callback):
                        download_success = True
                        break
            
            # Approach 3: Use yt-dlp as final fallback
            if not download_success:
                status_callback("üîÑ Trying yt-dlp fallback...", "blue")
                download_success = self.ytdlp_sharepoint_download(url, output_folder, filename, cookie_file, status_callback)
            
            if download_success:
                status_callback(f"‚úÖ Successfully downloaded: {filename}", "green")
            else:
                status_callback("‚ùå All download methods failed", "red")
                self.provide_manual_download_guidance(url, status_callback)
            
            return download_success
            
        except Exception as e:
            status_callback(f"‚ùå SharePoint download error: {str(e)}", "red")
            return False
    
    def get_sharepoint_direct_url(self, sharing_url, status_callback):
        """
        Convert SharePoint sharing URL to direct download URL
        Try multiple approaches
        """
        try:
            print(f"üîç Debug: get_sharepoint_direct_url - input: {sharing_url[:100]}...")
            
            # Approach 1: SharePoint API
            api_url = self.create_sharepoint_api_url(sharing_url)
            if api_url:
                status_callback("üîó Created SharePoint API URL", "green")
                return api_url
            
            # Approach 2: Direct file access
            direct_url = self.create_direct_file_url(sharing_url)
            if direct_url:
                status_callback("üîó Created direct file URL", "green")
                return direct_url
                
            # Approach 3: Download parameter modification
            download_url = self.modify_url_for_download(sharing_url)
            if download_url:
                status_callback("üîó Modified URL for download", "green")
                return download_url
            
            # Approach 4: Try to create a simple direct download URL
            simple_url = self.create_simple_download_url(sharing_url)
            if simple_url:
                status_callback("üîó Created simple download URL", "green")
                return simple_url
            
            # Approach 5: Try direct file access without download parameter
            direct_url = self.create_direct_file_url(sharing_url)
            if direct_url:
                status_callback("üîó Created direct file access URL", "green")
                return direct_url
            
            # Approach 6: Try SharePoint download.aspx format
            download_aspx_url = self.create_sharepoint_download_aspx_url(sharing_url)
            if download_aspx_url:
                status_callback("üîó Created SharePoint download.aspx URL", "green")
                return download_aspx_url
            
            return None
            
        except Exception as e:
            print(f"üîç Debug: Error in get_sharepoint_direct_url: {e}")
            return None
    
    def create_sharepoint_api_url(self, sharing_url):
        """Create proper SharePoint Graph API download URL"""
        try:
            import urllib.parse
            import base64
            import json
            
            print(f"üîç Debug: create_sharepoint_api_url - input: {sharing_url[:100]}...")
            
            # Extract sharing token from URL
            if ':u:/r/' in sharing_url:
                parts = sharing_url.split(':u:/r/')
                if len(parts) == 2:
                    base_url = parts[0]
                    encoded_path = parts[1]
                    
                    # Parse domain and site info
                    domain_parts = base_url.replace('https://', '').split('/')
                    domain = domain_parts[0]
                    
                    # Create Graph API URL using sharing token approach
                    sharing_url_encoded = base64.b64encode(sharing_url.encode()).decode().rstrip('=')
                    graph_url = f"https://graph.microsoft.com/v1.0/shares/u!{sharing_url_encoded}/root/content"
                    
                    print(f"üîç Debug: Created Graph API URL: {graph_url[:100]}...")
                    return graph_url
            
            return None
            
        except Exception as e:
            print(f"üîç Debug: Error creating SharePoint API URL: {e}")
            return None
    
    def create_direct_file_url(self, sharing_url):
        """Create direct file access URL"""
        try:
            print(f"üîç Debug: create_direct_file_url - input: {sharing_url[:100]}...")
            
            if ':u:/r/' in sharing_url:
                # Convert sharing URL to direct access URL
                parts = sharing_url.split(':u:/r/')
                if len(parts) == 2:
                    base_url = parts[0].rstrip('/')
                    path_part = parts[1]
                    
                    # Handle path properly - avoid duplicate 'personal/'
                    if path_part.startswith('personal/'):
                        clean_path = path_part
                    else:
                        clean_path = f"personal/{path_part}"
                    
                    # Create direct file access URL
                    direct_url = f"{base_url}/{clean_path}"
                    print(f"üîç Debug: Created direct file URL: {direct_url[:100]}...")
                    print(f"üîç Debug: Clean path: {clean_path}")
                    return direct_url
            
            return None
            
        except Exception as e:
            print(f"üîç Debug: Error in create_direct_file_url: {e}")
            return None
    
    def create_sharepoint_download_aspx_url(self, sharing_url):
        """Create SharePoint download.aspx URL"""
        try:
            print(f"üîç Debug: create_sharepoint_download_aspx_url - input: {sharing_url[:100]}...")
            
            if ':u:/r/' in sharing_url:
                # Convert sharing URL to download.aspx format
                parts = sharing_url.split(':u:/r/')
                if len(parts) == 2:
                    base_url = parts[0].rstrip('/')
                    path_part = parts[1]
                    
                    # Handle path properly
                    if path_part.startswith('personal/'):
                        clean_path = path_part
                    else:
                        clean_path = f"personal/{path_part}"
                    
                    # Create SharePoint download.aspx URL
                    download_url = f"{base_url}/{clean_path}/_layouts/15/download.aspx"
                    print(f"üîç Debug: Created download.aspx URL: {download_url[:100]}...")
                    print(f"üîç Debug: Clean path: {clean_path}")
                    return download_url
            
            return None
            
        except Exception as e:
            print(f"üîç Debug: Error in create_sharepoint_download_aspx_url: {e}")
            return None
    
    def get_sharepoint_download_url_from_page(self, sharing_url, session, status_callback):
        """Extract download URL by parsing SharePoint page content"""
        try:
            # First, get the page content
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.9',
                'Referer': sharing_url,
            }
            
            response = session.get(sharing_url, headers=headers, timeout=30)
            response.raise_for_status()
            
            # Parse HTML to find download links
            import re
            
            # Look for download.aspx links
            download_patterns = [
                r'href=["\']([^"\']*download\.aspx[^"\']*)["\']',
                r'href=["\']([^"\']*downloadRedirect[^"\']*)["\']',
                r'"downloadUrl":\s*"([^"]*)"',
                r'"@microsoft.graph.downloadUrl":\s*"([^"]*)"'
            ]
            
            for pattern in download_patterns:
                matches = re.findall(pattern, response.text, re.IGNORECASE)
                for match in matches:
                    if match.startswith('http'):
                        return match
                    elif match.startswith('/'):
                        from urllib.parse import urljoin
                        return urljoin(sharing_url, match)
            
            return None
        except Exception as e:
            status_callback(f"Error parsing SharePoint page: {str(e)}", "orange")
            return None
    
    def modify_url_for_download(self, sharing_url):
        """Modify URL to force download"""
        try:
            print(f"üîç Debug: modify_url_for_download - input: {sharing_url[:100]}...")
            
            if '_layouts/15/onedrive.aspx' in sharing_url:
                # Replace with download.aspx
                download_url = sharing_url.replace('onedrive.aspx', 'download.aspx')
                print(f"üîç Debug: Modified URL for download: {download_url[:100]}...")
                return download_url
            
            return None
            
        except Exception as e:
            print(f"üîç Debug: Error in modify_url_for_download: {e}")
            return None
    
    def create_simple_download_url(self, sharing_url):
        """Create a simple direct download URL for SharePoint"""
        try:
            print(f"üîç Debug: create_simple_download_url - input: {sharing_url[:100]}...")
            
            if ':u:/r/' in sharing_url:
                # Convert sharing URL to simple download URL
                parts = sharing_url.split(':u:/r/')
                if len(parts) == 2:
                    base_url = parts[0].rstrip('/')
                    path_part = parts[1]
                    
                    # Remove duplicate 'personal/' if exists
                    if path_part.startswith('personal/'):
                        clean_path = path_part
                    else:
                        clean_path = f"personal/{path_part}"
                    
                    # Create simple download URL by adding download parameter
                    simple_url = f"{base_url}/{clean_path}?download=1"
                    print(f"üîç Debug: Created simple download URL: {simple_url[:100]}...")
                    print(f"üîç Debug: Clean path: {clean_path}")
                    return simple_url
            
            return None
            
        except Exception as e:
            print(f"üîç Debug: Error in create_simple_download_url: {e}")
            return None
    
    def extract_filename_from_url(self, url):
        """
        Enhanced filename extraction for SharePoint URLs
        Properly handles URL encoding and extracts complete filename with extension
        """
        try:
            import urllib.parse
            import re
            
            print(f"üîç Debug: extract_filename_from_url - URL: {url[:150]}...")
            
            # Method 1: Extract from the end of the URL path (most reliable for SharePoint)
            if ':u:/r/' in url:
                # Split and get the path part
                path_part = url.split(':u:/r/')[1] if ':u:/r/' in url else url
                
                # Remove query parameters first
                if '?' in path_part:
                    path_part = path_part.split('?')[0]
                
                # URL decode the entire path
                decoded_path = urllib.parse.unquote(path_part)
                print(f"üîç Debug: decoded_path: {decoded_path}")
                
                # Split by '/' and find the last part that contains a file extension
                path_segments = decoded_path.split('/')
                print(f"üîç Debug: path_segments: {path_segments}")
                
                # Look for filename from the end
                for i in range(len(path_segments) - 1, -1, -1):
                    segment = path_segments[i].strip()
                    # Check if segment contains file extension
                    if re.search(r'\.(rar|zip|pdf|docx?|xlsx?|pptx?|mp[34]|avi|mkv|mov|wmv|flv|webm|m4v)$', segment, re.IGNORECASE):
                        print(f"üîç Debug: Found filename with extension: {segment}")
                        return segment
                
                # If no extension found, take the last non-empty segment and try to determine extension
                for i in range(len(path_segments) - 1, -1, -1):
                    segment = path_segments[i].strip()
                    if segment and segment not in ['Documents', 'Shared Documents', 'personal']:
                        # Try to determine file type from context or assume common extension
                        filename = segment
                        
                        # Check if this looks like a course/lesson name, assume it's a RAR file
                        if any(keyword in filename.lower() for keyword in ['kh√≥a h·ªçc', 'course', 'lesson', 'b√†i', 'ch∆∞∆°ng']):
                            filename += '.rar'
                        
                        print(f"üîç Debug: Filename without extension, assumed: {filename}")
                        return filename
            
            # Method 2: Extract from 'id=' parameter (fallback)
            if 'id=' in url:
                id_match = re.search(r'id=([^&]*)', url)
                if id_match:
                    id_value = urllib.parse.unquote(id_match.group(1))
                    if '/' in id_value:
                        potential_filename = id_value.split('/')[-1]
                        if '.' in potential_filename:
                            print(f"üîç Debug: Filename from id parameter: {potential_filename}")
                            return potential_filename
            
            # Method 3: Look for filename patterns in the entire URL
            filename_patterns = [
                r'/([^/]+\.(rar|zip|pdf|docx?|xlsx?|pptx?|mp[34]|avi|mkv|mov|wmv|flv|webm|m4v))(?:\?|$)',
                r'([^/\s]+\.(rar|zip|pdf|docx?|pptx?|mp[34]|avi|mkv|mov|wmv|flv|webm|m4v))(?:\?|$)'
            ]
            
            for pattern in filename_patterns:
                matches = re.findall(pattern, url, re.IGNORECASE)
                if matches:
                    filename = matches[-1][0] if isinstance(matches[-1], tuple) else matches[-1]
                    print(f"üîç Debug: Filename from pattern matching: {filename}")
                    return filename
            
            # Default fallback
            print("üîç Debug: No filename found, using default")
            return "sharepoint_download.rar"
            
        except Exception as e:
            print(f"üîç Debug: Error in extract_filename_from_url: {e}")
            return "sharepoint_download_error.rar"
    
    def create_multiple_download_urls(self, sharing_url):
        """
        Create multiple potential download URLs from SharePoint sharing URL
        """
        download_urls = []
        
        try:
            import urllib.parse
            
            if ':u:/r/' in sharing_url:
                parts = sharing_url.split(':u:/r/')
                if len(parts) == 2:
                    base_url = parts[0]
                    path_part = parts[1]
                    
                    # Remove query parameters for clean path
                    clean_path = path_part.split('?')[0] if '?' in path_part else path_part
                    
                    # Method 1: Direct file access
                    direct_url = f"{base_url.rstrip('/')}/{clean_path}"
                    download_urls.append(direct_url)
                    
                    # Method 2: Add download parameter
                    download_param_url = f"{base_url.rstrip('/')}/{clean_path}?download=1"
                    download_urls.append(download_param_url)
                    
                    # Method 3: Force download with different parameter
                    force_download_url = f"{base_url.rstrip('/')}/{clean_path}?download=true&noRedirect=true"
                    download_urls.append(force_download_url)
                    
                    # Method 4: Use download.aspx with proper encoding
                    if 'personal/' in clean_path:
                        source_url = f"{base_url.rstrip('/')}/{clean_path}"
                        download_aspx_url = f"{base_url.rstrip('/')}/_layouts/15/download.aspx?SourceUrl={urllib.parse.quote(source_url)}"
                        download_urls.append(download_aspx_url)
                    
                    # Method 5: Use guestaccess.aspx for shared files
                    guest_url = f"{base_url.rstrip('/')}/_layouts/15/guestaccess.aspx?docid={urllib.parse.quote(clean_path)}&authkey=&e="
                    download_urls.append(guest_url)
                    
                    # Method 6: Try SharePoint API approach
                    try:
                        # Extract site path for API
                        if 'personal/' in clean_path:
                            site_path = clean_path.split('personal/')[1].split('/')[0]
                            api_path = clean_path.split('personal/')[1]
                            api_url = f"{base_url.rstrip('/')}/_api/v2.0/drives/b!{site_path}/root:/{api_path}:/content"
                            download_urls.append(api_url)
                    except Exception as e:
                        print(f"üîç Debug: Error creating API URL: {e}")
                    
                    # Method 7: Try direct file access with different encoding
                    try:
                        # URL encode the path properly
                        encoded_path = urllib.parse.quote(clean_path, safe='')
                        direct_encoded_url = f"{base_url.rstrip('/')}/{encoded_path}"
                        download_urls.append(direct_encoded_url)
                    except Exception as e:
                        print(f"üîç Debug: Error creating encoded URL: {e}")
                    
                    # Method 8: Try SharePoint modern download approach
                    try:
                        if 'personal/' in clean_path:
                            # Use modern SharePoint download pattern
                            modern_url = f"{base_url.rstrip('/')}/_layouts/15/download.aspx?UniqueId={urllib.parse.quote(clean_path)}&SourceUrl={urllib.parse.quote(f'{base_url.rstrip('/')}/{clean_path}')}"
                            download_urls.append(modern_url)
                    except Exception as e:
                        print(f"üîç Debug: Error creating modern URL: {e}")
                    
                    # Method 9: Try SharePoint file preview approach
                    try:
                        if 'personal/' in clean_path:
                            # Use file preview pattern that often leads to download
                            preview_url = f"{base_url.rstrip('/')}/_layouts/15/filepreview.aspx?SourceUrl={urllib.parse.quote(f'{base_url.rstrip('/')}/{clean_path}')}"
                            download_urls.append(preview_url)
                    except Exception as e:
                        print(f"üîç Debug: Error creating preview URL: {e}")
            
            print(f"üîç Debug: Created {len(download_urls)} download URLs")
            for i, url in enumerate(download_urls):
                print(f"üîç Debug: URL #{i+1}: {url[:100]}...")
            
            return download_urls
            
        except Exception as e:
            print(f"üîç Debug: Error creating download URLs: {e}")
            return []
    
    def download_from_url(self, url, output_folder, filename, session, status_callback):
        """
        Download file from URL with proper validation and progress tracking
        """
        try:
            import requests
            # Setup SharePoint-specific headers with proper authentication
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'application/octet-stream,application/rar,application/zip,application/pdf,application/octet-stream,*/*',
                'Accept-Language': 'en-US,en;q=0.9,vi;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive',
                'Referer': 'https://moithuvemmo-my.sharepoint.com/',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'same-origin',
                'Upgrade-Insecure-Requests': '1',
                'X-Requested-With': 'XMLHttpRequest',
                'Cache-Control': 'no-cache',
                'Pragma': 'no-cache',
                'DNT': '1',
                'Origin': 'https://moithuvemmo-my.sharepoint.com',
                'Sec-Fetch-User': '?1'
            }
            
            # Initialize SharePoint session first (important for authentication)
            try:
                # First, visit the main SharePoint site to establish session
                init_url = url.split('/:u:/r/')[0] if ':u:/r/' in url else url
                print(f"üîç Debug: Initializing session with: {init_url}")
                
                init_response = session.get(init_url, headers=headers, timeout=30)
                print(f"üîç Debug: Session init status: {init_response.status_code}")
                
                # Wait a bit for session to establish
                import time
                time.sleep(1)
                
            except Exception as e:
                print(f"üîç Debug: Session initialization failed: {e}")
            
            # Make request with established session
            response = session.get(url, headers=headers, stream=True, timeout=60, allow_redirects=True)
            
            print(f"üîç Debug: Response status: {response.status_code}")
            print(f"üîç Debug: Response headers: {dict(list(response.headers.items())[:5])}")
            
            # Check if response is successful
            if response.status_code == 200:
                content_type = response.headers.get('content-type', '').lower()
                content_length = response.headers.get('content-length')
                
                # Validate this is actually a file download, not an HTML page
                if 'text/html' in content_type:
                    print(f"üîç Debug: Received HTML page, not file download")
                    print(f"üîç Debug: Content-Type: {content_type}")
                    print(f"üîç Debug: Content-Length: {content_length}")
                    
                    # Check if this might be a redirect page
                    if 'redirect' in response.text.lower() or 'window.location' in response.text.lower():
                        print(f"üîç Debug: Detected redirect page, following...")
                        # Try to extract redirect URL
                        import re
                        redirect_match = re.search(r'window\.location\s*=\s*["\']([^"\']+)["\']', response.text)
                        if redirect_match:
                            redirect_url = redirect_match.group(1)
                            print(f"üîç Debug: Found redirect URL: {redirect_url}")
                            # Follow redirect
                            response = session.get(redirect_url, headers=headers, stream=True, timeout=60)
                            if response.status_code == 200:
                                content_type = response.headers.get('content-type', '').lower()
                                if 'text/html' not in content_type:
                                    print(f"üîç Debug: Redirect successful, now downloading file")
                                else:
                                    print(f"üîç Debug: Redirect still leads to HTML page")
                                    return False
                            else:
                                return False
                    
                    # Check for SharePoint-specific patterns that might indicate file access
                    elif 'access denied' in response.text.lower() or 'sign in' in response.text.lower():
                        print(f"üîç Debug: SharePoint access denied - authentication required")
                        return False
                    elif 'file not found' in response.text.lower() or '404' in response.text.lower():
                        print(f"üîç Debug: SharePoint file not found")
                        return False
                    elif 'sharepoint' in response.text.lower() and 'error' in response.text.lower():
                        print(f"üîç Debug: SharePoint error page detected")
                        return False
                    else:
                        print(f"üîç Debug: Unknown HTML page, analyzing content...")
                        # Try to extract any file-related information
                        if 'download' in response.text.lower() or 'file' in response.text.lower():
                            print(f"üîç Debug: Page contains download/file references, might be accessible")
                            # Don't immediately fail, some SharePoint pages contain file info
                        else:
                            return False
                
                # Check content length
                total_size = int(content_length) if content_length else 0
                if total_size == 0:
                    print(f"üîç Debug: Content length is 0 or unknown")
                    # Don't immediately fail, some servers don't send content-length
                
                # Create output directory
                os.makedirs(output_folder, exist_ok=True)
                file_path = os.path.join(output_folder, filename)
                
                # Download with progress tracking
                downloaded = 0
                with open(file_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            downloaded += len(chunk)
                            
                            if total_size > 0:
                                percent = (downloaded / total_size) * 100
                                status_callback(f"üì• Downloading: {percent:.1f}% ({downloaded:,}/{total_size:,} bytes)", "blue")
                            else:
                                status_callback(f"üì• Downloading: {downloaded:,} bytes", "blue")
                
                # Validate download
                if downloaded > 0:
                    status_callback(f"‚úÖ Download completed: {downloaded:,} bytes", "green")
                    return True
                else:
                    os.remove(file_path)  # Remove empty file
                    print(f"üîç Debug: Downloaded 0 bytes, removing empty file")
                    return False
            else:
                print(f"üîç Debug: HTTP {response.status_code}: {response.reason}")
                
                # Handle SharePoint-specific error responses
                if response.status_code == 403:
                    print(f"üîç Debug: Access forbidden - authentication required")
                    # Try to extract error message from response
                    if 'text/html' in response.headers.get('content-type', ''):
                        if 'access denied' in response.text.lower():
                            print(f"üîç Debug: Access denied message detected")
                        elif 'sign in' in response.text.lower():
                            print(f"üîç Debug: Sign-in required message detected")
                
                elif response.status_code == 404:
                    print(f"üîç Debug: File not found")
                
                elif response.status_code == 401:
                    print(f"üîç Debug: Unauthorized - invalid or expired cookies")
                
                return False
                
        except requests.exceptions.RequestException as e:
            print(f"üîç Debug: Request error: {e}")
            return False
        except Exception as e:
            print(f"üîç Debug: Download error: {e}")
            return False
    
    def find_download_link(self, html_content, base_url):
        """T√¨m download link trong HTML"""
        try:
            import re
            print(f"üîç Debug: find_download_link - base_url: {base_url[:100]}...")
            print(f"üîç Debug: HTML content length: {len(html_content)}")
            
            # T√¨m c√°c link c√≥ th·ªÉ download
            download_patterns = [
                r'href=["\']([^"\']*\.(?:rar|zip|pdf|docx?|xlsx?|mp[34]|avi|mkv))["\']',
                r'href=["\']([^"\']*download[^"\']*)["\']',
                r'href=["\']([^"\']*_layouts/15/download[^"\']*)["\']',
                r'href=["\']([^"\']*_layouts/15/onedrive\.aspx[^"\']*)["\']',
                r'href=["\']([^"\']*_layouts/15/guestaccess\.aspx[^"\']*)["\']',
                r'href=["\']([^"\']*_layouts/15/start\.aspx[^"\']*)["\']',
                r'href=["\']([^"\']*_layouts/15/viewlsts\.aspx[^"\']*)["\']',
            ]
            
            for i, pattern in enumerate(download_patterns):
                print(f"üîç Debug: Pattern {i+1}: {pattern}")
                matches = re.findall(pattern, html_content, re.IGNORECASE)
                print(f"üîç Debug: Matches for pattern {i+1}: {matches}")
                
                for match in matches:
                    print(f"üîç Debug: Processing match: {match}")
                    if match.startswith('http'):
                        print(f"üîç Debug: Found absolute URL: {match}")
                        return match
                    elif match.startswith('/'):
                        # T·∫°o absolute URL
                        from urllib.parse import urljoin
                        absolute_url = urljoin(base_url, match)
                        print(f"üîç Debug: Created absolute URL: {absolute_url}")
                        return absolute_url
            
            # T√¨m ki·∫øm n√¢ng cao: T√¨m c√°c button ho·∫∑c link c√≥ text li√™n quan ƒë·∫øn download
            advanced_patterns = [
                r'<a[^>]*download[^>]*href=["\']([^"\']+)["\'][^>]*>',
                r'<button[^>]*onclick=["\'][^"\']*download[^"\']*["\'][^>]*>',
                r'<input[^>]*type=["\']button["\'][^>]*onclick=["\'][^"\']*download[^"\']*["\'][^>]*>',
            ]
            
            for i, pattern in enumerate(advanced_patterns):
                print(f"üîç Debug: Advanced Pattern {i+1}: {pattern}")
                matches = re.findall(pattern, html_content, re.IGNORECASE)
                print(f"üîç Debug: Advanced Matches for pattern {i+1}: {matches}")
                
                for match in matches:
                    print(f"üîç Debug: Processing advanced match: {match}")
                    if match.startswith('http'):
                        print(f"üîç Debug: Found advanced absolute URL: {match}")
                        return match
                    elif match.startswith('/'):
                        from urllib.parse import urljoin
                        absolute_url = urljoin(base_url, match)
                        print(f"üîç Debug: Created advanced absolute URL: {absolute_url}")
                        return absolute_url
            
            print("üîç Debug: Kh√¥ng t√¨m th·∫•y download link n√†o")
            return None
        except Exception as e:
            print(f"üîç Debug: Error in find_download_link: {e}")
            return None
    
    def download_from_direct_link(self, download_link, output_folder, filename, cookie_file, status_callback):
        """T·∫£i file t·ª´ direct link"""
        try:
            import requests
            
            status_callback(f"üì• ƒêang t·∫£i file t·ª´ direct link...", "blue")
            
            # Headers ƒë·ªÉ gi·∫£ l·∫≠p browser
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': '*/*',
                'Accept-Language': 'en-US,en;q=0.9',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
                'Referer': 'https://moithuvemmo-my.sharepoint.com/',
            }
            
            # X·ª≠ l√Ω cookies n·∫øu c√≥
            cookies = None
            if cookie_file and os.path.exists(cookie_file):
                try:
                    from utils.cookies import load_cookies_from_file
                    cookies = load_cookies_from_file(cookie_file)
                    print(f"üîç Debug: Loaded cookies from: {cookie_file}")
                except Exception as e:
                    print(f"üîç Debug: Error loading cookies: {e}")
            
            # T·∫£i file v·ªõi cookies v√† headers
            response = requests.get(download_link, headers=headers, cookies=cookies, stream=True, timeout=60)
            response.raise_for_status()
            
            # L·∫•y k√≠ch th∆∞·ªõc file
            total_size = int(response.headers.get('content-length', 0))
            
            # T·∫°o ƒë∆∞·ªùng d·∫´n file
            file_path = os.path.join(output_folder, filename)
            
            # T·∫£i file v·ªõi progress
            downloaded = 0
            with open(file_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        downloaded += len(chunk)
                        if total_size > 0:
                            percent = (downloaded / total_size) * 100
                            status_callback(f"üì• ƒêang t·∫£i: {percent:.1f}% ({downloaded}/{total_size} bytes)", "blue")
                else:
                            status_callback(f"üì• ƒêang t·∫£i: {downloaded} bytes", "blue")
            
            status_callback(f"‚úÖ Ho√†n t·∫•t t·∫£i file: {filename}", "green")
            return True
            
        except Exception as e:
            status_callback(f"‚ùå L·ªói t·∫£i t·ª´ direct link: {str(e)}", "red")
            return False
    
    def download_sharepoint_direct(self, url, output_folder, filename, cookie_file, status_callback):
        """Ph∆∞∆°ng ph√°p download SharePoint tr·ª±c ti·∫øp"""
        try:
            print(f"üîç Debug: download_sharepoint_direct - URL: {url[:100]}...")
            status_callback("üîç Th·ª≠ ph∆∞∆°ng ph√°p SharePoint tr·ª±c ti·∫øp...", "blue")
            
            # T·∫°o URL download tr·ª±c ti·∫øp cho SharePoint
            if ':u:/r/' in url:
                # Chuy·ªÉn ƒë·ªïi sharing URL th√†nh download URL
                download_url = self.create_sharepoint_download_url(url)
                if download_url:
                    print(f"üîç Debug: Created download URL: {download_url[:100]}...")
                    status_callback("üîó ƒê√£ t·∫°o download URL, ƒëang t·∫£i...", "green")
                    
                    # T·∫£i file tr·ª±c ti·∫øp
                    return self.download_from_direct_link(download_url, output_folder, filename, cookie_file, status_callback)
            
            # N·∫øu kh√¥ng ph·∫£i sharing URL, th·ª≠ ph∆∞∆°ng ph√°p kh√°c
            if '_layouts/15/onedrive.aspx' in url:
                # T·∫°o URL download t·ª´ OneDrive
                download_url = self.create_onedrive_download_url(url)
                if download_url:
                    print(f"üîç Debug: Created OneDrive download URL: {download_url[:100]}...")
                    status_callback("üîó ƒê√£ t·∫°o OneDrive download URL, ƒëang t·∫£i...", "green")
                    
                    # T·∫£i file tr·ª±c ti·∫øp
                    return self.download_from_direct_link(download_url, output_folder, filename, cookie_file, status_callback)
            
            print("üîç Debug: Kh√¥ng th·ªÉ t·∫°o download URL")
            return False
            
        except Exception as e:
            print(f"üîç Debug: Error in download_sharepoint_direct: {e}")
            status_callback(f"‚ùå L·ªói ph∆∞∆°ng ph√°p SharePoint tr·ª±c ti·∫øp: {str(e)}", "red")
            return False
    
    def download_sharepoint_file_multi_approach(self, sharing_url, output_folder, cookie_file, status_callback):
        """Try multiple approaches to download SharePoint files"""
        import requests
        filename = self.extract_filename_from_url(sharing_url)
        session = requests.Session()
        
        # Load cookies if available
        if cookie_file and os.path.exists(cookie_file):
            try:
                from utils.cookies import load_cookies_from_file
                cookies = load_cookies_from_file(cookie_file)
                if cookies:
                    session.cookies.update(cookies)
                    status_callback("üç™ Cookies loaded successfully", "green")
            except Exception as e:
                status_callback(f"Warning: Could not load cookies: {e}", "orange")
        
        # Approach 1: Graph API
        status_callback("üîÑ Trying Microsoft Graph API...", "blue")
        if self.try_graph_api_download(sharing_url, output_folder, filename, session, status_callback):
            return True
        
        # Approach 2: Direct page parsing
        status_callback("üîÑ Trying direct page parsing...", "blue")
        if self.try_page_parsing_download(sharing_url, output_folder, filename, session, status_callback):
            return True
        
        # Approach 3: URL manipulation
        status_callback("üîÑ Trying URL manipulation...", "blue")
        if self.try_url_manipulation_download(sharing_url, output_folder, filename, session, status_callback):
            return True
        
        # Approach 4: yt-dlp with special config
        status_callback("üîÑ Trying yt-dlp as final fallback...", "blue")
        return self.try_ytdlp_sharepoint(sharing_url, output_folder, cookie_file, status_callback)
    
    def try_graph_api_download(self, sharing_url, output_folder, filename, session, status_callback):
        """Try downloading using Microsoft Graph API"""
        try:
            graph_url = self.create_sharepoint_api_url(sharing_url)
            if not graph_url:
                return False
            
            # Add Microsoft Graph headers
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': '*/*',
                'Authorization': 'Bearer anonymous'  # For public shares
            }
            
            response = session.get(graph_url, headers=headers, stream=True, timeout=60)
            
            if response.status_code == 200:
                return self.save_file_with_progress(response, output_folder, filename, status_callback)
            
            return False
        except Exception as e:
            status_callback(f"Graph API failed: {str(e)}", "orange")
            return False
    
    def try_page_parsing_download(self, sharing_url, output_folder, filename, session, status_callback):
        """Try downloading by parsing SharePoint page content"""
        try:
            download_url = self.get_sharepoint_download_url_from_page(sharing_url, session, status_callback)
            if download_url:
                response = session.get(download_url, stream=True, timeout=60)
                if response.status_code == 200:
                    return self.save_file_with_progress(response, output_folder, filename, status_callback)
            return False
        except Exception as e:
            status_callback(f"Page parsing failed: {str(e)}", "orange")
            return False
    
    def try_url_manipulation_download(self, sharing_url, output_folder, filename, session, status_callback):
        """Try downloading using URL manipulation methods"""
        try:
            # Try simple download URL
            simple_url = self.create_simple_download_url(sharing_url)
            if simple_url:
                response = session.get(simple_url, stream=True, timeout=60)
                if response.status_code == 200:
                    return self.save_file_with_progress(response, output_folder, filename, status_callback)
            
            # Try direct file URL
            direct_url = self.create_direct_file_url(sharing_url)
            if direct_url:
                response = session.get(direct_url, stream=True, timeout=60)
                if response.status_code == 200:
                    return self.save_file_with_progress(response, output_folder, filename, status_callback)
            
            return False
        except Exception as e:
            status_callback(f"URL manipulation failed: {str(e)}", "orange")
            return False
    
    def try_ytdlp_sharepoint(self, sharing_url, output_folder, cookie_file, status_callback):
        """Try downloading using yt-dlp as final fallback"""
        try:
            status_callback("üîÑ Using yt-dlp fallback method...", "blue")
            return self.download_onedrive_file(sharing_url, output_folder, cookie_file, status_callback)
        except Exception as e:
            status_callback(f"yt-dlp fallback failed: {str(e)}", "orange")
            return False
    
    def handle_sharepoint_error_response(self, response, status_callback):
        """Handle SharePoint-specific error responses"""
        try:
            if response.headers.get('content-type', '').startswith('application/json'):
                error_data = response.json()
                if 'error' in error_data:
                    error_msg = error_data['error'].get('message', 'Unknown SharePoint error')
                    error_code = error_data['error'].get('code', 'Unknown')
                    status_callback(f"SharePoint API Error: {error_code} - {error_msg}", "red")
                    
                    # Provide specific guidance based on error code
                    if error_code == 'InvalidRequest':
                        status_callback("üí° Try: Check if the sharing link is still valid", "blue")
                    elif error_code == 'InvalidRequest':
                        status_callback("üí° Try: Ensure cookies are valid and up-to-date", "blue")
                    elif error_code == 'NotFound':
                        status_callback("üí° Try: Verify the file path in the sharing URL", "blue")
                        
                    return False
        except Exception:
            pass
        
        # Generic HTTP error handling
        status_callback(f"HTTP {response.status_code}: {response.reason}", "red")
        if response.status_code == 403:
            status_callback("üí° Authentication required - check cookies", "blue")
        elif response.status_code == 404:
            status_callback("üí° File not found - check sharing URL", "blue")
        elif response.status_code == 400:
            status_callback("üí° Bad request - trying alternative methods", "blue")
        
        return False
    
    def save_file_with_progress(self, response, output_folder, filename, status_callback):
        """Save file with progress tracking and validation"""
        try:
            total_size = int(response.headers.get('content-length', 0))
            file_path = os.path.join(output_folder, filename)
            
            # Ensure directory exists
            os.makedirs(output_folder, exist_ok=True)
            
            downloaded = 0
            with open(file_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        downloaded += len(chunk)
                        
                        if total_size > 0:
                            percent = (downloaded / total_size) * 100
                            status_callback(f"üì• Downloading: {percent:.1f}% ({downloaded:,}/{total_size:,} bytes)", "blue")
                        else:
                            status_callback(f"üì• Downloading: {downloaded:,} bytes", "blue")
            
            # Validate file was actually downloaded
            if downloaded == 0:
                os.remove(file_path)  # Remove empty file
                status_callback("‚ùå Downloaded file is empty - removing", "red")
                return False
            
            status_callback(f"‚úÖ Successfully downloaded: {filename} ({downloaded:,} bytes)", "green")
            return True
            
        except Exception as e:
            status_callback(f"Error saving file: {str(e)}", "red")
            return False
    
    def create_sharepoint_download_url(self, sharing_url):
        """
        Create proper SharePoint download URL from sharing URL
        Handle :u:/r/ format correctly
        """
        try:
            import urllib.parse
            print(f"üîç Debug: create_sharepoint_download_url - input: {sharing_url[:100]}...")
            
            if ':u:/r/' in sharing_url:
                # Split the URL properly
                parts = sharing_url.split(':u:/r/')
                if len(parts) == 2:
                    base_url = parts[0].rstrip('/')
                    path_part = parts[1]
                    
                    # Parse the path to extract file information
                    decoded_path = urllib.parse.unquote(path_part)
                    print(f"üîç Debug: decoded_path: {decoded_path[:100]}...")
                    
                    # Create SharePoint API download URL
                    # Format: https://domain.sharepoint.com/_api/v2.0/...
                    if 'personal/' in path_part:
                        # Extract personal site path
                        personal_path = path_part.split('personal/')[1]
                        site_path = personal_path.split('/')[0]
                        
                        # Construct API download URL
                        api_url = f"{base_url}/_api/v2.0/drives/b!{site_path}/root:/{decoded_path}:/content"
                        print(f"üîç Debug: Created API download URL: {api_url[:100]}...")
                        return api_url
                    
                    # Fallback: Create direct download URL
                    download_url = f"{base_url}/personal/{path_part}/_layouts/15/download.aspx"
                    print(f"üîç Debug: Created fallback download URL: {download_url[:100]}...")
                    return download_url
                
            return None
            
        except Exception as e:
            print(f"üîç Debug: Error in create_sharepoint_download_url: {e}")
            return None
    
    def create_onedrive_download_url(self, onedrive_url):
        """T·∫°o download URL t·ª´ OneDrive URL"""
        try:
            print(f"üîç Debug: create_onedrive_download_url - input: {onedrive_url[:100]}...")
            
            # Format: .../_layouts/15/onedrive.aspx?id=...&parent=...
            if '_layouts/15/onedrive.aspx' in onedrive_url:
                # Thay th·∫ø onedrive.aspx b·∫±ng download.aspx
                download_url = onedrive_url.replace('onedrive.aspx', 'download.aspx')
                print(f"üîç Debug: Created OneDrive download URL: {download_url[:100]}...")
                return download_url
            
            return None
            
        except Exception as e:
            print(f"üîç Debug: Error in create_onedrive_download_url: {e}")
            return None
    
    def convert_sharepoint_sharing_url(self, sharing_url):
        """Chuy·ªÉn ƒë·ªïi SharePoint sharing URL th√†nh URL download"""
        try:
            print(f"üîç Debug: convert_sharepoint_sharing_url - input: {sharing_url[:100]}...")
            
            # Format: https://domain.sharepoint.com/:u:/r/personal/.../Documents/.../filename.rar
            if ':u:/r/' in sharing_url:
                # T√°ch URL th√†nh c√°c ph·∫ßn
                base_parts = sharing_url.split(':u:/r/')
                if len(base_parts) == 2:
                    base_url = base_parts[0]
                    path_part = base_parts[1]
                    
                    # T√¨m ph·∫ßn Documents trong path
                    if 'Documents' in path_part:
                        # T·∫°o URL m·ªõi v·ªõi format OneDrive
                        new_url = f"{base_url}/personal/{path_part}"
                        print(f"üîç Debug: Converted URL: {new_url[:100]}...")
                        return new_url
                    
                    # N·∫øu kh√¥ng c√≥ Documents, th·ª≠ format kh√°c
                    else:
                        # T·∫°o URL v·ªõi _layouts/15/onedrive.aspx
                        new_url = f"{base_url}/personal/{path_part}/_layouts/15/onedrive.aspx"
                        print(f"üîç Debug: Converted URL (onedrive): {new_url[:100]}...")
                        return new_url
            
            print("üîç Debug: Kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi SharePoint sharing URL")
            return None
            
        except Exception as e:
            print(f"üîç Debug: Error in convert_sharepoint_sharing_url: {e}")
            return None
    
    def fallback_download_method(self, url, output_folder, filename, cookie_file, status_callback):
        """Ph∆∞∆°ng ph√°p fallback cho SharePoint"""
        try:
            status_callback("üîÑ Th·ª≠ ph∆∞∆°ng ph√°p fallback...", "blue")
            
            # Th·ª≠ s·ª≠ d·ª•ng yt-dlp v·ªõi c·∫•u h√¨nh ƒë·∫∑c bi·ªát
            import yt_dlp
            
            ydl_opts = {
                'outtmpl': os.path.join(output_folder, f'{filename}.%(ext)s'),
                'quiet': False,
                'noplaylist': True,
                'restrictfilenames': False,
                'retries': 10,
                'socket_timeout': 120,
                'extractor_retries': 10,
                'ignoreerrors': True,
                'no_warnings': False,
            }
            
            if cookie_file:
                ydl_opts['cookiefile'] = cookie_file
            
            def progress_hook(d):
                if d['status'] == 'downloading':
                    percent = d.get('_percent_str', '').strip()
                    speed = d.get('_speed_str', '').strip()
                    if status_callback:
                        status_callback(f"üì• ƒêang t·∫£i: {percent} | T·ªëc ƒë·ªô: {speed}", "blue")
                elif d['status'] == 'finished':
                    if status_callback:
                        status_callback("‚úÖ Ho√†n t·∫•t t·∫£i file!", "green")
            
            ydl_opts['progress_hooks'] = [progress_hook]
            
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                status_callback("üîç ƒêang th·ª≠ t·∫£i v·ªõi yt-dlp...", "blue")
                ydl.download([url])
            
            return True
            
        except Exception as e:
            status_callback(f"‚ùå Fallback method c≈©ng th·∫•t b·∫°i: {str(e)}", "red")
            return False

    def refresh_performance(self):
        """L√†m m·ªõi b√°o c√°o hi·ªáu su·∫•t"""
        if not self.system_optimizer:
            return
            
        try:
            # Get performance report
            report = self.system_optimizer.get_performance_report()
            
            # Clear previous content
            self.perf_text.delete("1.0", tk.END)
            
            if 'error' not in report:
                perf_info = f"CPU Usage: {report['cpu']['usage_percent']}% ({report['cpu']['status']})\n"
                perf_info += f"Memory Usage: {report['memory']['usage_percent']}% ({report['memory']['status']})\n"
                perf_info += f"Disk Usage: {report['disk']['usage_percent']}% ({report['disk']['status']})\n"
                perf_info += f"Available Memory: {report['memory']['available_gb']:.1f} GB\n"
                perf_info += f"Free Disk Space: {report['disk']['free_gb']:.1f} GB\n\n"
                
                # Optimal settings
                optimal = self.system_optimizer.get_optimal_settings()
                perf_info += "‚ö° C√†i ƒë·∫∑t t·ªëi ∆∞u:\n"
                for key, value in optimal.items():
                    perf_info += f"  {key}: {value}\n"
                    
                # External downloaders
                downloaders = self.system_optimizer.check_external_downloaders()
                perf_info += "\nüîß External Downloaders:\n"
                for name, available in downloaders.items():
                    status = "‚úÖ Available" if available else "‚ùå Not available"
                    perf_info += f"  {name}: {status}\n"
            else:
                perf_info = f"Error: {report['error']}"
                
            self.perf_text.insert("1.0", perf_info)
            
        except Exception as e:
            self.perf_text.delete("1.0", tk.END)
            self.perf_text.insert("1.0", f"Error refreshing performance: {e}")

    def load_optimization_tips(self):
        """T·∫£i m·∫πo t·ªëi ∆∞u h√≥a"""
        if not self.system_optimizer:
            return
            
        try:
            tips = self.system_optimizer.get_network_optimization_tips()
            
            # Clear previous content
            self.tips_text.delete("1.0", tk.END)
            
            tips_text = "üåê M·∫πo t·ªëi ∆∞u h√≥a m·∫°ng:\n\n"
            for i, tip in enumerate(tips, 1):
                tips_text += f"{i}. {tip}\n"
                
            self.tips_text.insert("1.0", tips_text)
            
        except Exception as e:
            self.tips_text.delete("1.0", tk.END)
            self.tips_text.insert("1.0", f"Error loading tips: {e}")
    
    def provide_manual_download_guidance(self, url, status_callback):
        """
        Provide manual download instructions when automated methods fail
        """
        status_callback("üí° Manual Download Instructions:", "blue")
        status_callback("1. Open the SharePoint URL in your browser", "blue")
        status_callback("2. Sign in to your Microsoft account if required", "blue")
        status_callback("3. Click the Download button or right-click ‚Üí Save As", "blue")
        status_callback("4. Check if the file requires special permissions", "blue")
        status_callback("", "blue")
        status_callback("üîß Troubleshooting Tips:", "blue")
        status_callback("‚Ä¢ Update your cookies file if authentication is required", "blue")
        status_callback("‚Ä¢ Verify the sharing link hasn't expired", "blue")
        status_callback("‚Ä¢ Try downloading a smaller file first to test access", "blue")
    
    def extract_download_links_from_page(self, url, session, status_callback):
        """Extract download links from SharePoint page content"""
        try:
            # Get the page content
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.9',
                'Referer': url,
            }
            
            response = session.get(url, headers=headers, timeout=30)
            response.raise_for_status()
            
            # Parse HTML to find download links
            import re
            
            # Look for download.aspx links
            download_patterns = [
                r'href=["\']([^"\']*download\.aspx[^"\']*)["\']',
                r'href=["\']([^"\']*downloadRedirect[^"\']*)["\']',
                r'"downloadUrl":\s*"([^"]*)"',
                r'"@microsoft.graph.downloadUrl":\s*"([^"]*)"'
            ]
            
            download_links = []
            for pattern in download_patterns:
                matches = re.findall(pattern, response.text, re.IGNORECASE)
                for match in matches:
                    if match.startswith('http'):
                        download_links.append(match)
                    elif match.startswith('/'):
                        from urllib.parse import urljoin
                        absolute_url = urljoin(url, match)
                        download_links.append(absolute_url)
            
            print(f"üîç Debug: Found {len(download_links)} download links")
            return download_links
            
        except Exception as e:
            status_callback(f"Error parsing SharePoint page: {str(e)}", "orange")
            return []
    
    def ytdlp_sharepoint_download(self, url, output_folder, filename, cookie_file, status_callback):
        """Use yt-dlp as final fallback for SharePoint downloads"""
        try:
            import yt_dlp
            
            ydl_opts = {
                'outtmpl': os.path.join(output_folder, filename),
                'quiet': False,
                'noplaylist': True,
                'restrictfilenames': False,
                'retries': 10,
                'socket_timeout': 120,
                'extractor_retries': 10,
                'ignoreerrors': True,
                'no_warnings': False,
            }
            
            if cookie_file:
                ydl_opts['cookiefile'] = cookie_file
            
            def progress_hook(d):
                if d['status'] == 'downloading':
                    percent = d.get('_percent_str', '').strip()
                    speed = d.get('_speed_str', '').strip()
                    if status_callback:
                        status_callback(f"üì• ƒêang t·∫£i: {percent} | T·ªëc ƒë·ªô: {speed}", "blue")
                elif d['status'] == 'finished':
                    if status_callback:
                        status_callback("‚úÖ Ho√†n t·∫•t t·∫£i file!", "green")
            
            ydl_opts['progress_hooks'] = [progress_hook]
            
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                status_callback("üîç ƒêang th·ª≠ t·∫£i v·ªõi yt-dlp...", "blue")
                ydl.download([url])
            
            return True
            
        except Exception as e:
            status_callback(f"‚ùå yt-dlp fallback failed: {str(e)}", "red")
            return False

    def update_line_numbers(self, event=None):
        """Update line numbers in the URL input area"""
        text = self.url_entry.get("1.0", tk.END)
        lines = text.splitlines()
        self.line_numbers.delete("1.0", tk.END)
        for i, line in enumerate(lines, 1):
            self.line_numbers.insert(tk.END, f"{i}\n")

    def highlight_current_line(self, event):
        """Highlight the current line in the URL input"""
        try:
            current_line = self.url_entry.index(tk.INSERT).split('.')[0]
            self.line_numbers.tag_remove("current_line", "1.0", tk.END)
            self.line_numbers.tag_add("current_line", f"{current_line}.0", f"{current_line}.end")
            self.line_numbers.tag_config("current_line", background="#e3f2fd", foreground="#1976d2")
        except Exception:
            pass

    def truncate_url(self, url, max_length=80):
        """Truncate long URLs to fit on one line"""
        if len(url) <= max_length:
            return url
        
        # Keep the beginning and end, truncate middle
        keep_start = max_length // 3
        keep_end = max_length // 3
        middle = "..."
        
        start = url[:keep_start]
        end = url[-keep_end:] if keep_end > 0 else ""
        
        return f"{start}{middle}{end}"
    
    def format_url_for_display(self, url, line_number):
        """Format URL for display in status messages"""
        if len(url) > 60:
            return f"{line_number}. {self.truncate_url(url, 60)}"
        return f"{line_number}. {url}"
    
    def get_line_number(self, url):
        """Get the line number of a URL in the input text"""
        text = self.url_entry.get("1.0", tk.END)
        lines = text.splitlines()
        for i, line in enumerate(lines, 1):
            if line.strip() == url.strip():
                return i
        return 1  # Default to line 1 if not found

    def update_onedrive_line_numbers(self, event=None):
        """Update line numbers in the OneDrive URL input area"""
        text = self.onedrive_url_entry.get("1.0", tk.END)
        lines = text.splitlines()
        self.onedrive_line_numbers.delete("1.0", tk.END)
        for i, line in enumerate(lines, 1):
            self.onedrive_line_numbers.insert(tk.END, f"{i}\n")

    def highlight_onedrive_current_line(self, event):
        """Highlight the current line in the OneDrive URL input"""
        try:
            current_line = self.onedrive_url_entry.index(tk.INSERT).split('.')[0]
            self.onedrive_line_numbers.tag_remove("current_line", "1.0", tk.END)
            self.onedrive_line_numbers.tag_add("current_line", f"{current_line}.0", f"{current_line}.end")
            self.onedrive_line_numbers.tag_config("current_line", background="#e3f2fd", foreground="#1976d2")
        except Exception:
            pass

    def parse_and_display_progress(self, status_text, line_number):
        """Parse th√¥ng tin fragment v√† hi·ªÉn th·ªã ti·∫øn tr√¨nh chi ti·∫øt (n·∫øu label t·ªìn t·∫°i)"""
        try:
            # Parse fragment information
            if "Fragment:" in status_text and hasattr(self, 'fragment_progress_label') and self.fragment_progress_label:
                import re
                fragment_match = re.search(r'Fragment:\s*(\d+)/(\d+)', status_text)
                if fragment_match:
                    current_frag = int(fragment_match.group(1))
                    total_frags = int(fragment_match.group(2))
                    remaining_frags = total_frags - current_frag
                    
                    fragment_text = f"üìä Fragment: {current_frag}/{total_frags} (c√≤n {remaining_frags})"
                    try:
                        self.fragment_progress_label.config(text=fragment_text, fg="#3b5998")
                    except Exception:
                        pass
                    
                    # T√≠nh ph·∫ßn trƒÉm fragment
                    frag_percent = (current_frag / total_frags) * 100 if total_frags else 0
                    fragment_text += f" - {frag_percent:.1f}%"
                    try:
                        self.fragment_progress_label.config(text=fragment_text, fg="#3b5998")
                    except Exception:
                        pass
            
            # Parse speed v√† ETA
            if "T·ªëc ƒë·ªô:" in status_text and hasattr(self, 'speed_eta_label') and self.speed_eta_label:
                import re
                speed_match = re.search(r'T·ªëc ƒë·ªô:\s*([^|]+)', status_text)
                eta_match = re.search(r'C√≤n l·∫°i:\s*([^|]+)', status_text)
                
                speed_text = ""
                if speed_match:
                    speed = speed_match.group(1).strip()
                    speed_text = f"‚ö° T·ªëc ƒë·ªô: {speed}"
                
                if eta_match:
                    eta = eta_match.group(1).strip()
                    speed_text += f" | ‚è±Ô∏è C√≤n l·∫°i: {eta}"
                
                if speed_text:
                    try:
                        self.speed_eta_label.config(text=speed_text, fg="#27ae60")
                    except Exception:
                        pass
                    
        except Exception:
            # an to√†n: b·ªè qua l·ªói parse hi·ªÉn th·ªã
            pass
    
    def clear_progress_display(self):
        """X√≥a th√¥ng tin ti·∫øn tr√¨nh chi ti·∫øt n·∫øu c√°c label t·ªìn t·∫°i"""
        if hasattr(self, 'fragment_progress_label') and self.fragment_progress_label:
            try:
                self.fragment_progress_label.config(text="")
            except Exception:
                pass
        if hasattr(self, 'speed_eta_label') and self.speed_eta_label:
            try:
                self.speed_eta_label.config(text="")
            except Exception:
                pass
